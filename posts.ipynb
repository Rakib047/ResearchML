{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5000, 9)\n",
      "Posts data exported successfully\n"
     ]
    }
   ],
   "source": [
    "import praw\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "# Set up Reddit API credentials\n",
    "user_agent = \"Scraper 1.0 by /u/Then_Basil_7613\"\n",
    "reddit = praw.Reddit(\n",
    "    client_id=\"JZvwf0yO8TYu4TnCVVkhdQ\",\n",
    "    client_secret=\"V46c7n3SENTe5BCyCYDvnQsQQ-XlRA\",\n",
    "    user_agent=user_agent\n",
    ")\n",
    "\n",
    "# Create a list to store submission information\n",
    "posts_data = []\n",
    "\n",
    "# Track number of entries collected\n",
    "count = 0\n",
    "MAX_POSTS = 5000  # Adjust this as needed\n",
    "\n",
    "# Define subreddit\n",
    "subreddit = reddit.subreddit('AskReddit')\n",
    "\n",
    "# Collect submissions in a backward manner\n",
    "last_submission = None\n",
    "\n",
    "while count < MAX_POSTS:\n",
    "    try:\n",
    "        # Define how many posts to collect in each iteration (chunk size)\n",
    "        limit_per_iteration = 1000\n",
    "\n",
    "        # Get new posts starting from the last post collected (if any)\n",
    "        if last_submission:\n",
    "            submissions = subreddit.new(limit=limit_per_iteration, params={\"before\": last_submission})\n",
    "        else:\n",
    "            submissions = subreddit.new(limit=limit_per_iteration)\n",
    "\n",
    "        # Store posts data\n",
    "        post_count_in_iteration = 0\n",
    "\n",
    "        for submission in submissions:\n",
    "            # Extract submission data\n",
    "            post = {\n",
    "                'User': submission.author.name if submission.author else 'Deleted',\n",
    "                'Post Title': submission.title,\n",
    "                'Content': submission.selftext,  # The content of the post (important for linguistic analysis)\n",
    "                'Score': submission.score,  # Upvotes received, can indicate post engagement\n",
    "                'Comments Count': submission.num_comments,  # Number of comments, useful for understanding engagement\n",
    "                'Upvote Ratio': submission.upvote_ratio,  # Ratio of upvotes to total votes\n",
    "                'Flair': submission.link_flair_text if submission.link_flair_text else 'None',  # Flair can help classify types of posts\n",
    "                'Date': pd.to_datetime(submission.created_utc, unit='s'),\n",
    "                'Post ID': submission.id  # To link comments to the post\n",
    "            }\n",
    "\n",
    "            posts_data.append(post)\n",
    "            count += 1\n",
    "            post_count_in_iteration += 1\n",
    "\n",
    "            # Track the last submission id to use it for the next iteration\n",
    "            last_submission = submission.name\n",
    "\n",
    "            # Stop if we have collected enough posts\n",
    "            if count >= MAX_POSTS:\n",
    "                break\n",
    "\n",
    "        # If no new posts were collected in the iteration, we might have reached the end of available data\n",
    "        if post_count_in_iteration == 0:\n",
    "            print(\"No more posts available to collect.\")\n",
    "            break\n",
    "\n",
    "        # Pause to avoid rate limits after each iteration\n",
    "        time.sleep(2)\n",
    "\n",
    "    except Exception as e:\n",
    "        # Handle rate limits or unexpected errors\n",
    "        print(f\"An error occurred: {e}\")\n",
    "        print(\"Sleeping for 60 seconds before retrying...\")\n",
    "        time.sleep(60)\n",
    "\n",
    "# Create DataFrame from the collected data\n",
    "posts_df = pd.DataFrame(posts_data)\n",
    "\n",
    "print(posts_df.shape)\n",
    "\n",
    "# Export the DataFrame to a CSV file\n",
    "posts_df.to_csv('AskReddit_posts.csv', index=False)\n",
    "\n",
    "print(\"Posts data exported successfully\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
